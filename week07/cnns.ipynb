{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Собираем нашу первую свёрточную нейросеть \n",
    "\n",
    "Пришло время построить нашу первую свёрточную нейросеть. Будем использовать для этого датасет [CIFAR-10](https://paperswithcode.com/sota/image-classification-on-cifar-10). Набор данных включает в себя цветные изображения из 10 различных классов.\n",
    "\n",
    "<img src=\"https://paperswithcode.com/media/datasets/CIFAR-10-0000000431-b71f61c0_U5n3Glr.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Смотрим на данные \n",
    "\n",
    "Скачаем и приготовим данные. Буквально через минуту в наших руках окажутся $60 000$ ($50 000$ для обучения, $10 000$ для валидации) цветных картинок размера $32 \\times 32$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.hub import _get_torch_home\n",
    "\n",
    "# На Linux датасет скачается в ~/.cache/torch/datasets, но можете выбрать любую другую папку\n",
    "datasets_path = Path(_get_torch_home()) / 'datasets'\n",
    "\n",
    "dataset_train = torchvision.datasets.CIFAR10(\n",
    "    datasets_path, train=True, download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "dataset_valid = torchvision.datasets.CIFAR10(\n",
    "    datasets_path, train=False, download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "print(dataset_train.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем несколько рандомных картинок из тренировочной выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "n = 10\n",
    "\n",
    "random_indices = np.random.choice(range(len(dataset_train)), size=n)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    X, y = dataset_train[idx]\n",
    "    plt.imshow(X.numpy().transpose(1, 2, 0))\n",
    "    plt.title(dataset_train.classes[y])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заранее создадим даталоадеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Полносвязная сетка \n",
    "\n",
    "Соберём полносвязную сетку по аналогии с тем, что мы делали в прошлый раз:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    <YOUR CODE>\n",
    ")\n",
    "# Не забудьте перенести модель на device!\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(dataset_train[0][0].unsqueeze(0).to(device))\n",
    "    assert y_pred.shape == (1, len(dataset_train.classes)), 'Модель должна выдавать по логиту для каждого класса'\n",
    "    del y_pred\n",
    "    assert next(model.parameters()).device.type == torch.device(device).type, 'Вы забыли перенести модель на device'\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кстати, заодно посмотрим на библиотеку `torchsummary`, позволяющую красиво печатать модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# на вход надо передать шейп входа модели, не считая размерности батча\n",
    "summary(model, dataset_train[0][0].shape, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируем параметры обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "learning_rate = 1e-3  # Кстати, это learning rate по умолчанию для Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заведём `criterion`, `opt`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения. Ничего необычного:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, opt, train_dataloader, valid_dataloader, num_epochs, device='cuda:0'):\n",
    "    history = {'loss_train': [], 'loss_valid': [], 'accuracy_valid': [], 'lr': []}\n",
    "    \n",
    "    with tqdm(range(1, num_epochs + 1)) as progress_bar:\n",
    "        for epoch in progress_bar:\n",
    "            epoch_losses_train = []\n",
    "            epoch_losses_valid = []\n",
    "            epoch_correct_predictions_valid = []\n",
    "            \n",
    "            # Трейн\n",
    "            for x_batch, y_batch in train_dataloader:\n",
    "                # Переносим батч на GPU\n",
    "                x_batch = <YOUR CODE>\n",
    "                y_batch = <YOUR CODE>\n",
    "\n",
    "                y_pred = <YOUR CODE>  # делаем предсказания\n",
    "                loss = <YOUR CODE>  # считаем лосс\n",
    "                \n",
    "                epoch_losses_train.append(loss.item())\n",
    "                assert np.isfinite(epoch_losses_train[-1])\n",
    "\n",
    "                # Считаем градиенты и делаем шаг оптимизатора, не забыв обнулить градиенты\n",
    "                <YOUR CODE>\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x_batch, y_batch in valid_dataloader:\n",
    "                    # Переносим батч на GPU\n",
    "                    x_batch = <YOUR CODE>\n",
    "                    y_batch = <YOUR CODE>\n",
    "\n",
    "                    y_pred = <YOUR CODE> # делаем предсказания\n",
    "                    loss = <YOUR CODE> # считаем лосс\n",
    "                    \n",
    "                    epoch_losses_valid.append(loss.item())\n",
    "                    assert np.isfinite(epoch_losses_valid[-1])\n",
    "\n",
    "                    batch_correct_predictions = torch.argmax(y_pred, dim=-1) == y_batch\n",
    "                    epoch_correct_predictions_valid.extend(batch_correct_predictions.to('cpu').numpy().tolist())\n",
    "                    \n",
    "            history['loss_train'].append(np.mean(epoch_losses_train))\n",
    "            history['loss_valid'].append(np.mean(epoch_losses_valid))\n",
    "            history['accuracy_valid'].append(np.mean(epoch_correct_predictions_valid))\n",
    "            history['lr'].append(opt.param_groups[0]['lr'])\n",
    "\n",
    "            # выводим статистику\n",
    "            stats = f'loss: {history[\"loss_valid\"][-1]:.5f}, accuracy: {history[\"accuracy_valid\"][-1]:.4f}'\n",
    "            print(f'Epoch: {epoch}, {stats}')\n",
    "            progress_bar.set_postfix_str(stats)\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательная функция, чтобы рисовать графики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(histories):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "\n",
    "    for name, history in histories.items():\n",
    "        train = plt.plot(history['loss_train'], label=f'{name} train')\n",
    "        plt.plot(history['loss_valid'], color=train[0].get_color(), linestyle='--', label=f'{name} valid')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Log loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "histories = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учим бейзлайн:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories['fc'] = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Свёрточная сетка "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Свёрточная нейронная сеть строится из нескольких разных типов слоёв: \n",
    "\n",
    "* [`nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) — Свёртка:\n",
    "    - **`in_channels`**: число каналов на входе;\n",
    "    - **`out_channels`**: число каналов на выходе; \n",
    "    - **`kernel_size`**: размер окна для свёртки;\n",
    "    - **`padding`**: какой ширины будет каёмка из нулей по краям картинки перед непосредственно свёрткой (если хотите, чтобы свёртка не меняла размер картинки, ставьте `padding=(kernel_size - 1) // 2`)\n",
    "* [`nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) — max pooling\n",
    "* [`nn.AvgPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html) — average pooling\n",
    "* [`nn.Flatten`](https://pytorch.org/docs/stable/generated/torch.flatten.html) — разворачивает картинку в вектор \n",
    "* [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) — полносвязный слой (fully-connected layer)\n",
    "* [`nn.ReLU`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) — функция активации. Естественно, можно выбрать любую другую\n",
    "\n",
    "\n",
    "В модели, которую мы определим ниже, на вход будут тензоры размера `(B, 1, 32, 32)`, а на выходе `(B, 10)` — это будет вероятность того, что объект относится к конкретному классу. `B`, как обычно, означает размерность батча. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте соберём свёрточную сеть наподобие LeNet-5: \n",
    "\n",
    "* Свёртка с $3$ каналами на входе (для цветного изображения), $32$ каналами на выходе, ядром $5 \\times 5$ и `padding` таким, чтобы размер изображения не менялся\n",
    "* ReLU\n",
    "* Max-pooling с ядром $2 \\times 2$ с шагом (strides) $2$ по обеим осям\n",
    "* Свёртка с $16$ каналами на выходе, ядром $5 \\times 5$ и `padding` таким, чтобы размер изображения не менялся\n",
    "* ReLU\n",
    "* Max-pooling с ядром $2 \\times 2$ с шагом (strides) $2$ по обеим осям\n",
    "* `Flatten`\n",
    "* Три полносвязных слоя с $120$, $60$ и $10$ нейронами соответственно. Здесь вам нужно будет посчитать или посмотреть, какого размера тензоры будут получаться после `Flatten`\n",
    "\n",
    "Это не то же самое, что оригинальный LeNet-5. Если вы заглянете в [оригинальную статью](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), то увидите там очень читабельное описание архитектуры, которая на современный взгляд выглядит странно.\n",
    "\n",
    "Реализацию оригинальной архитектуры на PyTorch можно посмотреть, например, [тут](https://github.com/maorshutman/lenet5-pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = <YOUR CODE>\n",
    "# Не забудьте перенести модель на device!\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(dataset_train[0][0].unsqueeze(0).to(device))\n",
    "    assert y_pred.shape == (1, len(dataset_train.classes)), 'Модель должна выдавать по логиту для каждого класса'\n",
    "    del y_pred\n",
    "    assert next(model.parameters()).device.type == torch.device(device).type, 'Вы забыли перенести модель на device'\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, dataset_train[0][0].shape, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories['conv'] = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, точность довольно сильно подскочила. Попробуйте поиграться числом параметров и слоёв так, чтобы их стало меньше, а качество сетки стало лучше. Попробуйте обучать нейросетку большее количество эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь могли быть ваши эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Готовые архитектуры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы посмотрим на реализации готовых архитектур, о которых мы говорили на лекции, в библиотеке torchvision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно указать pretrained=True, и тогда torchvision скачает готовые веса, обученные на ImageNet\n",
    "model = torchvision.models.alexnet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg16()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом месте давайте вспомним [ноутбук](https://github.com/dniku/neural_nets_dpo/blob/master/week01/pytorch_pretrained_model_demo.ipynb) с самого первого семинара. Там мы как раз использовали VGG-16!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_weights=False нужен из-за бага в scipy (попробуйте убрать этот параметр, и увидите предупреждение)\n",
    "model = torchvision.models.googlenet(init_weights=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Реализуем ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы руками изготовим модель, в точности повторяющую ResNet-18 из `torchvision.models` — настолько, что можно будет взять `state_dict` от одной модели и загрузить в другую. Этот процесс мы разделим на две части.\n",
    "\n",
    "В первую очередь мы сделаем так называемый residual block: модуль, содержащий внутри себя skip connection. Мы его сделаем так, чтобы при проходе через него у тензора могли измениться размеры или количество каналов. Он выглядит так:\n",
    "\n",
    "```\n",
    "--> conv -> bn -> relu -> conv -> bn --> + -->relu -->\n",
    " |                                       ↑\n",
    " '--------->optionally downsample--------'\n",
    "```\n",
    "\n",
    "При этом:\n",
    "\n",
    "* Все свёртки `conv` имеют kernel size 3x3 и padding=1\n",
    "* Изменение количества каналов и страйды есть только в первой свёртке `conv`\n",
    "* `downsample` — это последовательность из свёртки 1x1 (опционально со страйдами) и батчнорма\n",
    "* Во всех свёртках не используется bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь соберём саму модель. Она состоит из начала вида\n",
    "\n",
    "```\n",
    "conv -> bn -> relu -> maxpool\n",
    "```\n",
    "\n",
    "Затем 4 раза повторяется конструкция из серии `BasicBlock`. В ResNet-18 в каждой такой серии блоков 2.\n",
    "\n",
    "```\n",
    "layer1: BasicBlock(64, 64, stride=1) -> BasicBlock(64, 64, stride=1)\n",
    "layer2: BasicBlock(64, 128, stride=2) -> BasicBlock(128, 128, stride=1)\n",
    "layer3: BasicBlock(128, 256, stride=2) -> BasicBlock(256, 256, stride=1)\n",
    "layer4: BasicBlock(256, 512, stride=2) -> BasicBlock(512, 512, stride=1)\n",
    "```\n",
    "\n",
    "Наконец, в конце результат усредняется по пространственным размерностям и применяется один полносвязный слой, чтобы сделать итоговое предсказание. Таким образом, ResNet-18 — это логистическая регрессия поверх свёрточных фичей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes: int =1000) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 64)\n",
    "        self.layer2 = self._make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Это усредняет активации по пространственным размерностям\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        # В реализации ResNet-18 из torchvision используется ещё хитрая инициализация весов.\n",
    "        # Здесь мы это опускаем.\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_layer(in_channels: int, out_channels: int, stride: int = 1) -> nn.Sequential:\n",
    "        return nn.Sequential(\n",
    "            BasicBlock(in_channels, out_channels, stride),\n",
    "            BasicBlock(out_channels, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        <YOUR CODE>\n",
    "\n",
    "\n",
    "resnet18 = ResNet18()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и проверим, что она ведёт себя так же, как оригинал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = ResNet18()\n",
    "tv_resnet18 = torchvision.models.resnet18()\n",
    "\n",
    "tv_resnet18.load_state_dict(resnet18.state_dict())\n",
    "\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "torch.allclose(resnet18(x), tv_resnet18(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = ResNet18()\n",
    "tv_resnet18 = torchvision.models.resnet18()\n",
    "\n",
    "resnet18.load_state_dict(tv_resnet18.state_dict())\n",
    "\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "torch.allclose(resnet18(x), tv_resnet18(x))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
