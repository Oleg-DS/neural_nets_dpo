{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автоэнкодеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подход \n",
    "\n",
    "Автоэнкодеры - unsupervised (не требующие разметки данных) модели, которые находят применение как важные строительные блоки в огромном кол-ве сложных моделей и подходов.\n",
    "\n",
    "Идея автоэнкодера крайне проста - он состоит из двух нейронных сетей, называемых _энкодером_ и _декодером_, которые работают в тандеме. Задача энкодера - сжать исходный объект до вектора малой размерности, называемого _латентным кодом_ (или _скрытым представлением_). Задача декодера - восстановить из этого латентного кода исходный объект. \n",
    "\n",
    "![Архитектура автоэнкодера](https://miro.medium.com/max/600/1*nqzWupxC60iAH2dYrFT78Q.png)\n",
    "\n",
    "Источник картинки: [medium](https://medium.com/@birla.deepak26/autoencoders-76bb49ae6a8f)\n",
    "\n",
    "\n",
    "Обучение происходит путем уменьшения ошибки между исходным объектом и восстановленным:\n",
    "\n",
    "$$ \\operatorname{Loss} = \\sum \\operatorname{MSE}(x_i, dec(enc(x_i))) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Пишем простой автоэнкодер для MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём со скачивания датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.hub import _get_torch_home\n",
    "\n",
    "data_root = Path(_get_torch_home()) / 'datasets'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset_train = torchvision.datasets.MNIST(root=data_root, train=True, download=True, transform=transform)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=64, shuffle=True, num_workers=1)\n",
    "\n",
    "dataset_valid = torchvision.datasets.MNIST(root=data_root, train=False, download=True, transform=transform)\n",
    "dataloader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=64, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте реализуем и поиграемся с простым автоэнкодером, который берет изображения из MNIST и кодирует их в латентные коды длины `k`. В этом задании надо реализовать:\n",
    "\n",
    "* Encoder\n",
    "    * Четырехслойная полносвязная сеть с размерами слоёв `784-128-64-32-k`\n",
    "* Decoder\n",
    "    * Симметричная полносвязная сеть с размерами слоёв `k-32-64-128-784` **и сигмоида в конце**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTEncoder(nn.Module):\n",
    "    def __init__(self, lat_size):\n",
    "        super(MNISTEncoder, self).__init__()\n",
    "        self.lat_size = lat_size\n",
    "        \n",
    "        # Подсказка: пригодится nn.Flatten()\n",
    "        self.enc_net = <YOUR CODE>\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 4\n",
    "        assert x.shape[2] == x.shape[3] == 28\n",
    "        \n",
    "        z = self.enc_net(x)\n",
    "        \n",
    "        assert z.shape[0] == x.shape[0]\n",
    "        assert z.shape[1] == self.lat_size\n",
    "        \n",
    "        return z\n",
    "    \n",
    "class MNISTDecoder(nn.Module):\n",
    "    def __init__(self, lat_size):\n",
    "        super(MNISTDecoder, self).__init__()\n",
    "        self.lat_size = lat_size\n",
    "        \n",
    "        # Подсказка: пригодится nn.Unflatten() (посмотрите документацию!)\n",
    "        self.dec_net = <YOUR CODE>\n",
    "        \n",
    "    def forward(self, z):\n",
    "        assert z.shape[1] == self.lat_size\n",
    "        \n",
    "        x_rec = self.dec_net(z)\n",
    "        \n",
    "        assert x_rec.shape[1:] == (1, 28, 28)\n",
    "        assert x_rec.shape[0] == z.shape[0]\n",
    "        \n",
    "        return x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, lat_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.lat_size = lat_size\n",
    "        self.enc = MNISTEncoder(lat_size)\n",
    "        self.dec = MNISTDecoder(lat_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        return self.enc(x)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.dec(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте обучим автоэнкодер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader_train, optimizer, criterion, num_epochs=5, verbose_num_iters=32):\n",
    "    model.train()\n",
    "    loss_trace = []\n",
    "    \n",
    "    for epoch_i in range(num_epochs):        \n",
    "        print(f'Epoch {epoch_i + 1}')\n",
    "        for iter_i, batch in enumerate(dataloader_train):\n",
    "            x, _ = batch\n",
    "            x = x.to(device)\n",
    "\n",
    "            <YOUR CODE>\n",
    "            \n",
    "            loss_trace.append(loss.item())\n",
    "        \n",
    "            if (iter_i + 1) % verbose_num_iters == 0:\n",
    "                clear_output(wait=True)\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                \n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.xlabel('Iteration')\n",
    "                plt.ylabel('L2 loss (x, x_rec)')\n",
    "                plt.plot(loss_trace)\n",
    "                \n",
    "                for i in range(3):\n",
    "                    plt.subplot(2, 6, 4 + i)\n",
    "                    plt.axis('off')\n",
    "                    plt.imshow(x[i, 0].cpu().detach().numpy(), cmap='gray')\n",
    "                    \n",
    "                    plt.subplot(2, 6, 10 + i)\n",
    "                    plt.axis('off')\n",
    "                    plt.imshow(rec_x[i, 0].cpu().detach().numpy(), cmap='gray')\n",
    "                    \n",
    "                plt.show()\n",
    "                \n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве лосса будем использовать сумму квадратов разностей пикселей оригинального и восстановленного изображения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим модель с латентным кодом длины 8\n",
    "\n",
    "model = AutoEncoder(8)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_model(model, dataloader_train, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для довольно хорошего сжатия картинок из MNIST'a хватает всего 8 латентных переменных!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Структура и интерпретация латентного пространства\n",
    "\n",
    "Главная ценность автоэнкодера как модели - его латентный код. Он крайне информативный, т.к. он должен сохранять как можно больше важных деталей об объекте. Кроме того, само латентное пространство (множество латентных кодов всех объектов) - довольно плотное и отлично сохраняет структуру исходного пространства - например, похожие объекты в исходном пространстве будут находиться недалеко друг от друга в латентном. \n",
    "\n",
    "В этой части мы проиллюстрируем эти свойства."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Интерполяция латентных кодов\n",
    "\n",
    "Интерполяция латентного кода - это визуализация процесса движения от одной точки латентного пространства к другой. Обычно интерполируют по прямой - соединяют две точки, соответсвующие реальным объектам, отрезком и смотрят латентные коды через равные части этого отрезка. Для каждой промежуточной точки строят выход декодера. \n",
    "\n",
    "Давайте возьмем два случайных объекта из выборки и построим интерполяцию между ними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, _ in dataloader_train:\n",
    "    break\n",
    "    \n",
    "x1 = x[0].to(device)\n",
    "x2 = x[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 2))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis('off')\n",
    "plt.title('x1')\n",
    "plt.imshow(x1[0].cpu().detach().numpy(), cmap='gray')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis('off')\n",
    "plt.title('x2')\n",
    "plt.imshow(x2[0].cpu().detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получите латентные коды объектов\n",
    "z_1 = <YOUR CODE>\n",
    "z_2 = <YOUR CODE>\n",
    "assert z_1.shape == z_2.shape == torch.Size([1, 8])\n",
    "\n",
    "# постройте батч с интерполяцией этих латентных кодов по прямой в 11 точках (используйте функцию torch.linspace)\n",
    "linspace = <YOUR CODE>\n",
    "z_linspace = <YOUR CODE>\n",
    "assert z_linspace.shape == torch.Size([11, 8])\n",
    "\n",
    "# восстановите для всех латентных кодов изображения\n",
    "x_linspace = <YOUR CODE>\n",
    "assert x_linspace.shape == torch.Size([11, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нарисуем проинтерполированные объекты\n",
    "plt.figure(figsize=(11, 1))\n",
    "\n",
    "for i, d in enumerate(np.linspace(0, 1, 11)):\n",
    "    plt.subplot(1, 11, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'{d:.2}')\n",
    "    plt.imshow(x_linspace[i, 0].cpu().detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На интерполяции видно, как один объект плавно превращается в другой. Стоит заметить, что почти все промежуточные объекты тоже выглядят довольно правдопободно. Иногда такие интерполяции используют для того, чтобы расширить какой-то маленький датасет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Структура латентного пространства\n",
    "\n",
    "Теперь давайте обучим автоэнкодер с **2** латентными кодами, соберем эти латентные коды и нарисуем 2D scatter plot, где латентные коды подсвечены цветами классов исходных объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим автоэнкодер с 2 латентными кодами\n",
    "\n",
    "model_2d = AutoEncoder(2)\n",
    "model_2d.to(device)\n",
    "optimizer = torch.optim.Adam(model_2d.parameters(), lr=1e-3)\n",
    "\n",
    "train_model(model_2d, dataloader_train, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_codes_and_labels(dataloader, model, num_objects):\n",
    "    lat_codes = torch.empty((0, model.lat_size)).to(device)\n",
    "    labels = torch.empty((0)).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            <YOUR CODE>\n",
    "        \n",
    "            if lat_codes.shape[0] >= num_objects:\n",
    "                break\n",
    "\n",
    "    lat_codes = lat_codes[:num_objects].detach().cpu().numpy()\n",
    "    labels = labels[:num_objects].detach().cpu().numpy()\n",
    "\n",
    "    return lat_codes, labels\n",
    "    \n",
    "# соберем для 1000 случайных объектов их латентные коды и классы\n",
    "lat_codes, labels = get_latent_codes_and_labels(dataloader_train, model_2d, 1000)\n",
    "\n",
    "assert lat_codes.shape == (1000, 2)\n",
    "assert labels.shape == (1000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for cl in range(10):\n",
    "    lat_codes_class = lat_codes[labels == cl]\n",
    "    plt.scatter(lat_codes_class[:, 0], lat_codes_class[:, 1], label=f'{cl}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объекты одного и то же класса находятся в латентном пространстве близко друг к другу! При этом визуально похожие классы (1-4 или 4-9) тоже находятся в соседних областях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Применения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Semi-supervised learning\n",
    "\n",
    "Представим, что у нас следующая ситуация. Есть огромный датасет (тысячи объектов), но по тем или иным причинам размечена у него только малая часть (скажем, сотня) объектов. Например, причиной может быть дороговизна разметки или необходимость привлечения эксперта. Однако, мы хотим научиться решать эту задачу и должны как-то научиться использовать неразмеченные данные.\n",
    "\n",
    "В такой ситуации можно обучить автоэнкодер на всем датасете (размеченные + неразмеченные объекты) и использовать его латентные коды от размеченных объектов для обучения другой модели (например, из классического ML), которая не требовательна к объему данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предположим, у нас размечено только 1000 (из 50000) объектов из MNIST\n",
    "# возьмем для них латентные коды\n",
    "\n",
    "train_lat_codes, train_labels = get_latent_codes_and_labels(dataloader_train, model, 1000)\n",
    "\n",
    "assert train_lat_codes.shape == (1000, 8)\n",
    "assert train_labels.shape == (1000, )\n",
    "\n",
    "# так же обсчитаем весь валидационный сет\n",
    "test_lat_codes, test_labels = get_latent_codes_and_labels(dataloader_valid, model, 10000)\n",
    "\n",
    "assert test_lat_codes.shape == (10000, 8)\n",
    "assert test_labels.shape == (10000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим на них случайный лес\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = <YOUR CODE>\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = clf.predict(test_lat_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test accuracy: {(test_pred == test_labels).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Довольно хорошее качество для такого малого объема размеченных данных. Кроме того, мы смогли совместить преимущества нейросетевого и классического подхода и взять от них самое лучшее (нетребовательность к данным от ML и способность работы со сложноструктурированными данными от DL).\n",
    "\n",
    "Своего рода, это частный случай fine-tuning для ситуации, когда исходная сетка (энкодер) обучалась на неразмеченных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Denoising\n",
    "\n",
    "Кроме того, автоэнкодеры часто используют для очистки исходных данных от шума. Латентный код сохраняет только главную информацию об объекте, отбрасывая шумовые компоненты. \n",
    "\n",
    "Давайте реализуем функцию, которая обращает c вероятностью 0.1 каждый пиксель исходного изображения, и обучим на такой выборке автоэнкодер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlipRandomPixels:\n",
    "    def __init__(self, flip_ratio=0.1):\n",
    "        self.flip_ratio = flip_ratio\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        <YOUR CODE>\n",
    "        \n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    FlipRandomPixels(),\n",
    "])\n",
    "\n",
    "dataset_train_with_noise = torchvision.datasets.MNIST(root=data_root, train=True, transform=transform)\n",
    "dataloader_train_with_noise = torch.utils.data.DataLoader(dataset_train_with_noise, batch_size=64, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dataloader_train_with_noise:\n",
    "    break\n",
    "\n",
    "plt.figure(figsize=(11, 1))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x[i, 0].cpu().detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим автоэнкодер на зашумленных данных\n",
    "\n",
    "model_for_noise = AutoEncoder(8)\n",
    "model_for_noise.to(device)\n",
    "optimizer = torch.optim.Adam(model_for_noise.parameters(), lr=1e-3)\n",
    "\n",
    "train_model(model_for_noise, dataloader_train_with_noise, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Восстановленные объекты не содержат шума, которым мы испортили данные! \n",
    "\n",
    "Этот эксперимент должен Вам напомнить метод главных компонент (PCA) из классического ML, который тоже часто используют для сжатия данных и избавления от шума. PCA является частным случаем автоэнкодера с линейными энкодером и декодером."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acknowledgements: этот ноутбук основан на [восьмом семинаре](https://github.com/hse-ds/iad-deep-learning/blob/b958bd1/sem08/sem08.ipynb) курса ИАД DL."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
