{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Свёртки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с того, что пощупаем свёртки руками, без PyTorch. Воспользуемся для этого более низкоуровневым пакетом OpenCV, который можно импортировать как `cv2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Слово о тензорах и картинках\n",
    "\n",
    "Подгрузим какую-нибудь фотографию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_image(url):\n",
    "    response = requests.get(url)  # Делаем HTTP GET запрос на адрес\n",
    "    image = Image.open(io.BytesIO(response.content))  # Читаем ответ как картинку библиотекой PIL\n",
    "    image = np.asarray(image)  # Конвертируем PIL Image в numpy array\n",
    "    return image\n",
    "\n",
    "def show_image(image):\n",
    "    return Image.fromarray(image)\n",
    "\n",
    "image_url = 'https://www.mirf.ru/wp-content/uploads/2017/01/Drakarys.jpg'\n",
    "img = url_to_image(image_url)\n",
    "\n",
    "# Для наших экспериментов мы уменьшим размер картинки, потому что\n",
    "# в исходном качестве она занимает слишком много места на экране\n",
    "img = cv2.resize(img, (0, 0), fx=1 / 4, fy=1 / 4, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цветная картинка — это трёхмерный массив размерности `(высота, ширина, 3)`. Если мы попробуем такую картинку напечатать, то напечатается набор чисел. Каждому пикселю в такой картинке соответствуют 3 числа. Эти числа соответствуют яркостям красной (red), зелёной (green) и синей (blue) компоненты этого пикселя и меняются от 0 до 255. Такой формат записи цветов называется RGB. Бывают и другие форматы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape  # 270 строк, 480 столбцов, 3 цветовых канала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[200, 100]  # значения трёх каналов пикселя в 200-й строке и 100-м столбце"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0][:5]  # цвета 5 пикселей в верхней строке по шкале RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[2]  # цвета пикселей в строке 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно прибавить какое-нибудь число ко всем пикселям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но появляются артефакты. Почему?\n",
    "\n",
    "Дело в том, что картинка хранится с типом чисел `np.unt8`. Это означает, что каждое значение яркости компоненты RGB не только принимает значения только от 0 до 255, но и все арифметические операции с ними не смогут выходить за этот диапазон:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img[0, 0])\n",
    "print(img[0, 0] + 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если попробовать прибавить какое-нибудь большое число — например, 200 — ко всем значениям пикселей, то получится что-то странное:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img + 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такие же спецэффекты будут и с умножением:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если попытаться умножить число типа `np.uint8` на дробное число, то получится `np.float64`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img[0, 0] * 0.7)\n",
    "print((img[0, 0] * 0.7).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но его можно округлить обратно до `np.uint8`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image((img * 0.7).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть на то, как распределены на картинке пиксели различной яркости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "for i, color in enumerate('rgb'):\n",
    "    # Вытаскиваем из картинки один канал\n",
    "    channel = img[:, :, i]\n",
    "    # Собираем dict, где ключи — значения интенсивности пикселей, а значения — сколько раз они встречаются\n",
    "    cnt = Counter(channel.reshape(-1))\n",
    "    # Преобразуем dict в список\n",
    "    hist = [cnt[j] for j in range(256)]\n",
    "    # Отрисовываем его\n",
    "    plt.plot(hist, color=color)\n",
    "\n",
    "plt.xlim(-1, 256)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Свёртки\n",
    "\n",
    "Свёртка — это операция, которая превращает набор одних пикселей в другие. Обычно она осущствляется с помощью ядра свёртки, матрицы произвольного размера (часто $3 \\times 3$). Центральный элемент такой матрицы называется якорем свёртки. Удобно представлять себе, что он применяется к центральному пикселю. \n",
    "\n",
    "Работает свёртка очень просто. При вычислении нового значения выбранного пикселя изображения ядро свёртки прикладывается своим центром к этому пикселю. Далее вычисляется сумма произведений значений пикселей изображения на значения, накрывшего данный пиксель элемента ядра. Полученная сумма и является новым значением выбранного пикселя.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://github.com/FUlyankin/neural_nets_dpo/raw/e296fc12d4b3a7c523728feec5f56c59b6b35633/week08_conv/convolution_schematic.gif\">\n",
    "</center>\n",
    "\n",
    "Используя матрицы с разными коэффициентами, можно получать разные эффекты. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше нам понадобится вспомогательная функция для отображения нескольких картинок вплотную друг к другу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_multiple_images(images, figsize=(15, 12)):\n",
    "    f, axarr = plt.subplots(1, len(images), figsize=figsize)\n",
    "    for i, (title, image) in enumerate(images.items()):\n",
    "        assert image.dtype == np.uint8, 'Please cast your images to np.uint8'\n",
    "        if len(image.shape) == 3 and image.shape[2] == 1:\n",
    "            image = image.squeeze(2)\n",
    "        assert len(image.shape) in {2, 3}, 'Please ensure that your images are either black & white or RGB'\n",
    "        if len(image.shape) == 3:\n",
    "            axarr[i].imshow(image)\n",
    "        else:\n",
    "            axarr[i].imshow(image, cmap='gray')\n",
    "        axarr[i].set_title(title)\n",
    "        axarr[i].set_xticks([])\n",
    "        axarr[i].set_yticks([])\n",
    "    f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с тривиального эффекта. Попробуем применить такое ядро:\n",
    "\n",
    "$$ K = \\begin{pmatrix}\n",
    "0 & 0 & 0  \\\\\n",
    "0 & 0.7 & 0 \\\\         \n",
    "0 & 0 & 0 \n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = <YOUR CODE>\n",
    "dst = cv2.filter2D(img, kernel=kernel, ddepth=-1)\n",
    "\n",
    "show_multiple_images({'original': img, 'convolved': dst})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первой домашке мы видели, что для свёртки можно использовать функцию `scipy.signal.correlate2d`. Напрямую мы её сейчас использовать не можем, потому что изображение стало трёхмерным. Мы можем использовать более общую функцию `scipy.signal.correlate`, но по сравнению с `cv2.filter2D` понадобится указать больше параметров, а также привести типы вручную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "dst = scipy.signal.correlate(img, kernel[:, :, np.newaxis], mode='valid').astype(np.uint8)\n",
    "\n",
    "show_multiple_images({'original': img, 'convolved': dst})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кстати, обратите внимание: на лекции мы говорили, что при свёртке цветной картинки ядро должно быть трёхмерным, но здесь это не так. Подумайте, что тут происходит. Подсказка содержится в аргументах функции `scipy.signal.correlate`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем размыть изображение. В этом нам поможет следующее ядро размера $3 \\times 3$:\n",
    "\n",
    "$$ K = \\frac 1 9 \\cdot \\begin{pmatrix}\n",
    "1 & 1 & 1  \\\\\n",
    "1 & 1 & 1  \\\\\n",
    "1 & 1 & 1  \\\\\n",
    "\\end{pmatrix} $$\n",
    "\n",
    "<!--$$ K = \\frac{1}{n^2} \\cdot \\begin{pmatrix}\n",
    "1 & 1 & \\cdots & 1  \\\\\n",
    "1 & 1 & \\cdots & 1  \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & 1 & \\cdots & 1  \\\\\n",
    "\\end{pmatrix} $$-->\n",
    "\n",
    "Оно берёт пиксель в центре каждого квадрата размера $3 \\times 3$ и заменяет его на арифметическое среднее всех пикселей. Таким образом чёткость картинки уменьшается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = <YOUR CODE>\n",
    "dst = cv2.filter2D(img, kernel=kernel, ddepth=-1)\n",
    "\n",
    "show_multiple_images({'original': img, 'convolved': dst})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ядро для увеличения чёткости. Обратите внимание на относительно большое значение якоря.\n",
    "\n",
    "$$ \\frac 1 9 \\cdot \\begin{pmatrix}\n",
    "-1 & -1 & -1  \\\\\n",
    "-1 & 17 & -1 \\\\         \n",
    "-1 & -1 & -1 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "Почему значение якоря именно такое, а не, скажем, 15 или 20?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = <YOUR CODE>\n",
    "dst = cv2.filter2D(img, kernel=kernel, ddepth=-1)\n",
    "\n",
    "show_multiple_images({'original': img, 'convolved': dst})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забавно, что при повторном применении фильтра для увеличения чёткости, картинка покрывается шумом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.filter2D(img, kernel=kernel, ddepth=-1)\n",
    "for _ in range(2):\n",
    "    dst = cv2.filter2D(dst, kernel=kernel, ddepth=-1)\n",
    "\n",
    "show_multiple_images({'original': img, 'convolved': dst})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ещё один фильтр для сглаживания — gaussian blur. По-русски он обычно называется гауссовским. Строится он так. Сначала определяется одномерный фильтр как значения плотности нормального распределения:\n",
    "\n",
    "$$\n",
    "G_i = \\alpha *e^{-\\frac{(i-( \\texttt{ksize} -1)/2)^2} {2 \\cdot \\texttt{sigma}^2}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma=0 означает, что библиотека сама выберет такую sigma, которую считает правильной.\n",
    "# В документации можно найти формулу sigma = 0.3*((ksize-1)*0.5 - 1) + 0.8\n",
    "gauss1d = cv2.getGaussianKernel(ksize=5, sigma=0)\n",
    "gauss1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потом из него строится двумерный фильтр банальным произведением столбца на строку:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gauss1d @ gauss1d.T\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.filter2D(dst, kernel=kernel, ddepth=-1)\n",
    "show_multiple_images({'original': img, 'convolved': dst, 'blurred': blur})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это настолько часто используемый фильтр, что для него в OpenCV даже выделили отдельную функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(dst, (5, 5), 0)\n",
    "show_multiple_images({'original': img, 'convolved': dst, 'blurred': blur})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ядра бывают очень разными. Например:\n",
    "\n",
    "* С таким ядром яркость изображения увеличится (почему?):\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "-0.1 & 0.2 & -0.1  \\\\\n",
    "0.2 & 3 & 0.2 \\\\         \n",
    "-0.1 & 0.2 & -0.1 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "* С таким уменьшится (почему?):\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "-0.1 & 0.1 & -0.1  \\\\\n",
    " 0.1 & 0.5 & 0.1 \\\\         \n",
    "-0.1 & 0.1 & -0.1 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "* С таким изображение почти не изменится (почему? почему \"почти\"?):\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "0 & 0 & 0  \\\\\n",
    "0 & 1 & 0 \\\\         \n",
    "0 & 0 & 0 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "При хорошем знании линала, вы можете придумать самые безумные ядра. Попробуйте! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код для игры в фильтры "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Углубляемся в свёртку\n",
    "\n",
    "Попробуйте угадать, что делают следующие два фильтра. \n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "-1 & -1 & -1  \\\\\n",
    "0 & 0 & 0 \\\\         \n",
    "1 & 1 & 1 \n",
    "\\end{pmatrix}  $$\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "-1 & 0 & 1  \\\\\n",
    "-1 & 0 & 1 \\\\         \n",
    "-1 & 0 & 1 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "Внимание, ответ. Первый фильтр пытается понять насколько резко изменяется яркость картинки по вертикали и находит вертикальные границы. Второй фильтр пытается понять насколько резко изменяется картинка по горизонтали и находит горизонтальные границы. Если просуммировать применение этих фильтров, можно получить чёткое очертание границ картинки. Чем больше в матрицах цифры, тем более резкую разницу находят ядра. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = <YOUR CODE>\n",
    "kernel2 = <YOUR CODE>\n",
    "dst_h = cv2.filter2D(img, kernel=kernel1, ddepth=-1)\n",
    "dst_v = cv2.filter2D(img, kernel=kernel2, ddepth=-1)\n",
    "both = cv2.add(dst_h, dst_v)  # складываем две картинки, при переполнении np.uint8 останавливаемся на 0 или 255\n",
    "\n",
    "show_multiple_images({'horizontal': dst_h, 'both': both, 'vertical': dst_v})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если сначала обработать картинку ядром для повышения чёткости, потом заблюрить и наконец применить фильтр для поиска границ, они детектируются немного лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.full((3, 3), -1, dtype=np.float32)\n",
    "kernel[1, 1] = 17\n",
    "kernel /= 9\n",
    "dst = cv2.filter2D(img, kernel=kernel, ddepth=-1)\n",
    "dst = cv2.GaussianBlur(dst, (5, 5), 0)\n",
    "\n",
    "kernel1 = <YOUR CODE>\n",
    "kernel2 = <YOUR CODE>\n",
    "dst_h = cv2.filter2D(dst, kernel=kernel1, ddepth=-1)\n",
    "dst_v = cv2.filter2D(dst, kernel=kernel2, ddepth=-1)\n",
    "both = cv2.add(dst_h, dst_v)  # складываем две картинки, при переполнении np.uint8 останавливаемся на 0 или 255\n",
    "\n",
    "show_multiple_images({'horizontal': dst_h, 'both': both, 'vertical': dst_v})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри пакета есть своя функция для выделения границы. Она работает более агрессивно, чем наше ядро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = <YOUR CODE>\n",
    "kernel2 = <YOUR CODE>\n",
    "dst_h = cv2.filter2D(img, kernel=kernel1, ddepth=-1)\n",
    "dst_v = cv2.filter2D(img, kernel=kernel2, ddepth=-1)\n",
    "both = cv2.add(dst_h, dst_v)\n",
    "\n",
    "# Функция из OpenCV. Числа — это некоторые параметры алгоритма, мы не будем в это углубляться\n",
    "opencv_edges = cv2.Canny(img, 100, 200)\n",
    "\n",
    "show_multiple_images({'Our convolution': both, 'cv2.Canny': opencv_edges})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще, ядро поиска границы задаёт градиент картики по диагонали и градиент по вертикали. Можно побаловаться с более крутыми градиентами, в том числе диагональными.\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "0 & 1 & 2  \\\\\n",
    "-1 & 0 & 1 \\\\         \n",
    "-2 & -1 & 0 \n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = <YOUR CODE>\n",
    "kernel2 = <YOUR CODE>\n",
    "dst_h = cv2.filter2D(img, kernel=kernel1, ddepth=-1)\n",
    "dst_v = cv2.filter2D(img, kernel=kernel2, ddepth=-1)\n",
    "both = cv2.add(dst_h, dst_v)\n",
    "\n",
    "show_multiple_images({'top left → bottom right (\\\\)': dst_h, 'both': both, 'top right → bottom left (/)': dst_v})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже догадались, можно придумать фильры не только для поиска границ, но и для поиска других различных закономерностей, которые есть на картинке. \n",
    "\n",
    "Представим себе на секунду славный дивный мир, в котором бывают картинки только двух типов: с прямыми слэшами и с обратными (/ \\). При этом, эти слэши могут быть нарисованы на картинке где угодно. Пусть у нас есть две картинки. На одной из них слэш нарисован внизу справа, на второй сверху слева. Пройдёмся по нашим картинкам специальным ядром, которое ищет обратные слэши. После свёртки, мы получим на выходе две уменьшившиеся в размерах картинки, в каждой из которых будет фигурировать цифра два, как раз отвечающая за найденный обратный слэш.\n",
    "\n",
    "<img align=\"center\" src=\"https://github.com/FUlyankin/neural_nets_dpo/raw/e296fc12d4b3a7c523728feec5f56c59b6b35633/week08_conv/photo_1.png\" width=\"600\"> \n",
    "\n",
    "Если точно такое же ядро натравить на картинку без обратного слэша, оно не выдаст нам на выход никакой двойки. \n",
    "\n",
    "<img align=\"center\" src=\"https://github.com/FUlyankin/neural_nets_dpo/raw/e296fc12d4b3a7c523728feec5f56c59b6b35633/week08_conv/photo_2.png\" width=\"600\"> \n",
    "\n",
    "Получаем простейший классификатор картинок с слэшами. \n",
    "\n",
    "1. Проходимся по картинке ядром. \n",
    "2. Находим в итоговой матрице максимальный элемент.\n",
    "3. Если это двойка, на картинке изображён слэш. Если это единица, на картинке обратный слэш.\n",
    "\n",
    "Обратите внимание, что работа этого классификатора не зависит от того, где именно на картинке находится слэш. Именно так свёрточные нейронные сети и работают с картинками. Конечно же, в реальности закономерности на картинках на порядок сложнее. При этом, мы даже не знаем какими именно могут быть эти закономерности. Для того, чтобы их искать, в нейронную сетку добавляются ядра с неспецифицированными параметрами.\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "w_1 & w_2 & w_3  \\\\\n",
    "w_4 & w_5 & w_6 \\\\         \n",
    "w_7 & w_8 & w_9 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "Слои, на которых находятся эти ядра называются свёрточными. Параметры подбираются в ходе обучения нейронной сети по реальным данным и отражают в себе какие-то закономерности, найденные во время обучения на картинках. Представим, что наша нейронная сеть должна уметь распознавать лица. Добавим в неё несколько свёрточных слоёв. \n",
    "\n",
    "Первый слой будет находить простейшие элементы, такие как слэши, прямые чёрточки и извилистые чёрточки. Второй слой будет конструировать из элементов, найденных на первом слое, ещё более сложные штуки. В данном случае окружности и крестики. Третий слой будет конструировать из объектов, найденных на втором слое ещё более сложные объекты. Таким образом, мы, слой за слоем, будем собирать всё более и более сложные объекты до тех пор, пока не дойдём до лица. \n",
    "\n",
    "<img align=\"center\" src=\"https://github.com/FUlyankin/neural_nets_dpo/raw/e296fc12d4b3a7c523728feec5f56c59b6b35633/week08_conv/photo_3.png\" width=\"600\"> \n",
    "\n",
    "Обычно закономерности, которые находит свёрточная сеть сложно интерпретируемы. Тем не менее, мы можем забрать те закономерности, которые нашла нейросетка и использовать их в качестве регрессоров в какой-то более интерпретируемой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Наша первая свёрточная нейросеть \n",
    "\n",
    "Пришло время построить нашу первую свёрточную нейросеть. Будем использовать для этого датасет [CIFAR-10](https://paperswithcode.com/sota/image-classification-on-cifar-10). Набор данных включает в себя цветные изображения из 10 различных классов.\n",
    "\n",
    "<img src=\"https://paperswithcode.com/media/datasets/CIFAR-10-0000000431-b71f61c0_U5n3Glr.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Смотрим на данные \n",
    "\n",
    "Скачаеми приготовим данные. Буквально через минуту в наших руках окажутся $60 000$ ($50 000$ для обучения, $10 000$ для валидации) цветных картинок размера $32 \\times 32$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.hub import _get_torch_home\n",
    "\n",
    "# На Linux датасет скачается в ~/.cache/torch/datasets, но можете выбрать любую другую папку\n",
    "datasets_path = Path(_get_torch_home()) / 'datasets'\n",
    "\n",
    "dataset_train = torchvision.datasets.CIFAR10(\n",
    "    datasets_path, train=True, download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "dataset_valid = torchvision.datasets.CIFAR10(\n",
    "    datasets_path, train=False, download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "class_idx_to_name = (\n",
    "    'airplane', 'automobile', 'bird', 'cat',\n",
    "    'deer', 'dog', 'frog', 'horse',\n",
    "    'ship', 'truck',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем несколько рандомных картинок из тренировочной выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "n = 10\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(dataset_train[i][0].numpy().transpose(1, 2, 0))\n",
    "    plt.title(class_idx_to_name[dataset_train[i][1]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заранее создадим даталоадеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Полносвязная сетка \n",
    "\n",
    "Соберём полносвязную сетку по аналогии с тем, что мы делали в прошлый раз:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = <YOUR CODE>\n",
    "# Не забудьте перенести модель на GPU!\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кстати, заодно посмотрим на библиотеку `torchsummary`, позволяющую красиво печатать модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3 * 32 * 32,))  # на вход надо передать шейп входа модели, не считая размерности батча"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируем параметры обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 500\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заведём `criterion`, `opt`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения. Ничего необычного:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, opt, train_dataloader, valid_dataloader, device='cuda:0', flatten=False):\n",
    "    history = {'loss_train': [], 'loss_valid': [], 'accuracy_valid': [], 'lr': []}\n",
    "    \n",
    "    with tqdm(range(1, num_epochs + 1)) as progress_bar:\n",
    "        for epoch in progress_bar:\n",
    "            epoch_losses_train = []\n",
    "            epoch_losses_valid = []\n",
    "            epoch_accuracies_valid = []\n",
    "            \n",
    "            # Трейн\n",
    "            for x_batch, y_batch in train_dataloader:\n",
    "                if flatten:\n",
    "                    x_batch = x_batch.reshape(x_batch.shape[0], -1)\n",
    "\n",
    "                # Переносим батч на GPU\n",
    "                x_batch = <YOUR CODE>\n",
    "                y_batch = <YOUR CODE>\n",
    "\n",
    "                y_pred = <YOUR CODE>  # делаем предсказания\n",
    "                loss = <YOUR CODE>  # считаем лосс\n",
    "                \n",
    "                epoch_losses_train.append(loss.item())\n",
    "                assert np.isfinite(epoch_losses_train[-1])\n",
    "\n",
    "                # Считаем градиенты и делаем шаг оптимизатора, не забыв обнулить градиенты\n",
    "                <YOUR CODE>\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x_batch, y_batch in valid_dataloader:\n",
    "                    if flatten:\n",
    "                        x_batch = x_batch.reshape(x_batch.shape[0], -1)\n",
    "\n",
    "                    # Переносим батч на GPU\n",
    "                    x_batch = <YOUR CODE>\n",
    "                    y_batch = <YOUR CODE>\n",
    "\n",
    "                    y_pred = <YOUR CODE> # делаем предсказания\n",
    "                    loss = <YOUR CODE> # считаем лосс\n",
    "                    \n",
    "                    epoch_losses_valid.append(loss.item())\n",
    "                    assert np.isfinite(epoch_losses_valid[-1])\n",
    "\n",
    "                    epoch_accuracies_valid.extend((torch.argmax(y_pred, dim=-1) == y_batch).to('cpu').numpy().tolist())\n",
    "                    \n",
    "            history['loss_train'].append(np.mean(epoch_losses_train))\n",
    "            history['loss_valid'].append(np.mean(epoch_losses_valid))\n",
    "            history['accuracy_valid'].append(np.mean(epoch_accuracies_valid))\n",
    "            history['lr'].append(opt.param_groups[0]['lr'])\n",
    "\n",
    "            # выводим статистику\n",
    "            stats = f'loss: {history[\"loss_valid\"][-1]:.5f}, accuracy: {history[\"accuracy_valid\"][-1]:.4f}'\n",
    "            print(f'Epoch: {epoch}, {stats}')\n",
    "            progress_bar.set_postfix_str(stats)\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательная функция, чтобы рисовать графики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(histories):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "\n",
    "    for name, history in histories.items():\n",
    "        train = plt.plot(history['loss_train'], label=f'{name} train')\n",
    "        plt.plot(history['loss_valid'], color=train[0].get_color(), linestyle='--', label=f'{name} valid')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Log loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "histories = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учим бейзлайн:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories['fc'] = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Свёрточная сетка "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Свёрточная нейронная сеть строится из нескольких разных типов слоёв: \n",
    "\n",
    "* [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) — Свёртка:\n",
    "    - **in_channels**: число каналов на входе;\n",
    "    - **out_channels**: число каналов на выходе; \n",
    "    - **kernel_size**: размер окна для свёртки;\n",
    "    - **padding**: какой ширины будет каёмка из нулей по краям картинки перед непосредственно свёрткой (если хотите, чтобы свёртка не меняла размер картинки, ставьте `padding=(kernel_size - 1) // 2`)\n",
    "* [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) — max-pooling\n",
    "* [AvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html) — average pooling\n",
    "* [Flatten](https://pytorch.org/docs/stable/generated/torch.flatten.html) — разворачивает картинку в вектор \n",
    "* [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) — полносвязный слой (fully-connected layer)\n",
    "* [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) — функция активации. Естественно, можно выбрать любую другую\n",
    "\n",
    "\n",
    "В модели, которую мы определим ниже, на вход будут тензоры размера `(B, 1, 32, 32)`, а на выходе `(B, 10)` — это будет вероятность того, что объект относится к конкретному классу. `B`, как обычно, означает размерность батча. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте соберём свёрточную сеть наподобие LeNet-5: \n",
    "\n",
    "* Свёртка с $3$ каналами на входе (для цветного изображения), $32$ каналами на выходе, ядром $5 \\times 5$ и `padding` таким, чтобы размер изображения не менялся\n",
    "* ReLU\n",
    "* Max-pooling с ядром $2 \\times 2$ с шагом (strides) $2$ по обеим осям\n",
    "* Свёртка с $16$ каналами на выходе, ядром $5 \\times 5$ и `padding` таким, чтобы размер изображения не менялся\n",
    "* ReLU\n",
    "* Max-pooling с ядром $2 \\times 2$ с шагом (strides) $2$ по обеим осям\n",
    "* Дальше сделайте `Flatten` и сделайте два полносвязных слоя с ReLU и $120$ и $60$ нейронами\n",
    "\n",
    "Это не то же самое, что оригинальный LeNet-5. Если вы заглянете в [оригинальную статью](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), то увидите там очень читабельное описание архитектуры, которая на современный взгляд выглядит странно.\n",
    "\n",
    "Реализацию оригинальной архитектуры на PyTorch можно посмотреть, например, [тут](https://github.com/maorshutman/lenet5-pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = <YOUR CODE>\n",
    "# Не забудьте перенести модель на GPU!\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories['conv'] = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, точность довольно сильно подскочила. Попробуйте поиграться числом параметров и слоёв так, чтобы их стало меньше, а качество сетки стало лучше. Попробуйте обучать нейросетку большее количество эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь могли быть ваши эксперименты"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
