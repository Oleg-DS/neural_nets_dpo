{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "equal-acceptance",
   "metadata": {},
   "source": [
    "В этой тетрадке мы разберём те вещи, которые раньше мы заметали под ковёр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-christmas",
   "metadata": {},
   "source": [
    "# 1. Разминка: `.backward()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-prince",
   "metadata": {},
   "source": [
    "Не запуская эту ячейку, можете ли вы сказать, что она напечатает?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(-3., requires_grad=True)\n",
    "y = x**2\n",
    "y.backward()\n",
    "\n",
    "print('x =', x)\n",
    "print('y =', y)\n",
    "print('x.grad =', x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-guest",
   "metadata": {},
   "source": [
    "А что насчёт этой ячейки? Как будет выглядеть график?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-3, 3, 100, requires_grad=True)\n",
    "y = x**2\n",
    "y.sum().backward()\n",
    "\n",
    "plt.plot(x.detach(), y.detach(), label='y')\n",
    "plt.plot(x.detach(), x.grad, label='x.grad')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-pakistan",
   "metadata": {},
   "source": [
    "Посчитайте градиент функции\n",
    "\n",
    "$$\n",
    "f(w) = \\prod_{i,j} \\ln(\\ln(w_{ij} + 7))\n",
    "$$\n",
    "\n",
    "в точке `w = [[5,10], [1,2]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = <YOUR CODE>\n",
    "f = <YOUR CODE>\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-reality",
   "metadata": {},
   "source": [
    "# 2. Пишем слои руками"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-equality",
   "metadata": {},
   "source": [
    "Все слои торча, которые мы с вами уже использовали, являются наследниками класса `nn.Module`. Нас в нём будут больше всего интересовать методы `__init__` и `forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_identical_forward(torch_layer, my_layer, std=1, **kwargs):\n",
    "    for _ in range(10):\n",
    "        a = torch.randn(10, 3) * std\n",
    "        assert torch.allclose(torch_layer(a), my_layer(a), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-visibility",
   "metadata": {},
   "source": [
    "## 2.1. `nn.ReLU`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-publisher",
   "metadata": {},
   "source": [
    "В качестве примера посмотрим, как можно реализовать `ReLU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(nn.Module):  # наследуемся от nn.Module\n",
    "    def forward(self, x):\n",
    "        # На вход пришёл какой-то тензор x\n",
    "        return torch.maximum(x, torch.tensor(0))  # Возвращаем max(x, 0)\n",
    "\n",
    "assert_identical_forward(nn.ReLU(), ReLU())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-civilian",
   "metadata": {},
   "source": [
    "Разумеется, этим слоем можно пользоваться так же, как мы раньше пользовались стандартными слоями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = ReLU()\n",
    "\n",
    "x = torch.randn(2, 3)\n",
    "print(x)\n",
    "\n",
    "y = layer(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-still",
   "metadata": {},
   "source": [
    "## 2.2. Про шейпы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-carry",
   "metadata": {},
   "source": [
    "Дальше хотелось бы реализовать `nn.Softmax`, но там понадобится делить каждую строку тензора на знаменатель, единый для всей строки. Поймём, как это правильно сделать. Пусть у нас есть вот такой тензор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(15).reshape(5, 3)\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-southwest",
   "metadata": {},
   "source": [
    "Если просто сделать `a / a.sum(dim=1)`, то ничего не выйдет. Шейп `a` равен `(5, 3)`, `a.sum(dim=1)` — `(5,)`, и PyTorch не понимает, что мы от него хотим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.sum(dim=1))\n",
    "print(a.sum(dim=1).shape)\n",
    "print(a / a.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-printer",
   "metadata": {},
   "source": [
    "А вот если изменить шейп `a.sum(dim=1)` на `(5, 1)`, то сработает броадкастинг: PyTorch увидит, что мы пытаемся разделить тензор с шейпом `(5, 3)` на тензор с шейпом `(5, 1)`, и корректно размножит второй тензор вдоль столбцов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.sum(dim=1, keepdim=True))\n",
    "print(a.sum(dim=1, keepdim=True).shape)\n",
    "print(a / a.sum(dim=1, keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-gross",
   "metadata": {},
   "source": [
    "Давайте теперь попробуем написать вот такой слой:\n",
    "\n",
    "$$\n",
    "\\left[ \\operatorname{DivideBySum}(x) \\right]_{ij} = \\frac {x_{ij}} {\\sum_{k = 1}^n x_{ik}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DivideBySum(nn.Module):\n",
    "    def forward(self, x):\n",
    "        <YOUR CODE>\n",
    "\n",
    "assert_identical_forward(lambda x: x / x.sum(dim=1, keepdim=True), DivideBySum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-commerce",
   "metadata": {},
   "source": [
    "## 2.3. `nn.Softmax`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-arthritis",
   "metadata": {},
   "source": [
    "Можно написать `Softmax` прямо по определению:\n",
    "\n",
    "$$\n",
    "\\left[ \\operatorname{SoftmaxUnstable}(x) \\right]_{ij} = \\frac {\\exp (x_{ij})} {\\sum_{k = 1}^n \\exp (x_{ik})}\n",
    "$$\n",
    "\n",
    "Давайте попробуем это сделать и убедимся, что второй тест (передающий на вход слою числа порядка 1000) не проходится:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxUnstable(nn.Module):\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 2\n",
    "        <YOUR CODE>\n",
    "\n",
    "assert_identical_forward(nn.Softmax(dim=1), SoftmaxUnstable())\n",
    "assert_identical_forward(nn.Softmax(dim=1), SoftmaxUnstable(), std=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-burden",
   "metadata": {},
   "source": [
    "Вместо этого лучше писать Softmax, поделив числитель и знаменатель на наибольшую экспоненту:\n",
    "\n",
    "$$\n",
    "\\left[ \\operatorname{Softmax}(x) \\right]_{ij} = \\frac {\\exp (x_{ij} - x_{i \\text{, max}})} {\\sum_{k = 1}^n \\exp (x_{ik} - x_{i \\text{, max}})}, \\quad \\text{ где } x_{i \\text{, max}} = \\max_j x_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(nn.Module):\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 2\n",
    "        <YOUR CODE>\n",
    "\n",
    "assert_identical_forward(nn.Softmax(dim=1), Softmax())\n",
    "assert_identical_forward(nn.Softmax(dim=1), Softmax(), std=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-comparative",
   "metadata": {},
   "source": [
    "## 2.4. `nn.LogSoftmax`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-qatar",
   "metadata": {},
   "source": [
    "Аналогично `Softmax`, можно написать по определению и убедиться, что это не работает:\n",
    "\n",
    "$$\n",
    "\\left[ \\operatorname{LogSoftmaxUnstable}(x) \\right]_{ij} =\n",
    "\\log \\left[ \\operatorname{Softmax}(x) \\right]_{ij}\n",
    "$$\n",
    "\n",
    "Естественно, это не работает, если подставить `SoftmaxUnstable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSoftmaxVeryUnstable(nn.Module):\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 2\n",
    "        return torch.log(SoftmaxUnstable()(x))\n",
    "\n",
    "LogSoftmaxVeryUnstable()(torch.randn(10, 3) * 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-feeling",
   "metadata": {},
   "source": [
    "Но даже и с обычным `Softmax` тоже ничего не выходит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSoftmaxUnstable(nn.Module):\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 2\n",
    "        return torch.log(Softmax()(x))\n",
    "\n",
    "LogSoftmaxUnstable()(torch.randn(10, 3) * 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-notification",
   "metadata": {},
   "source": [
    "Вместо этого лучше сделать преобразование, аналогичное тому, которое мы сделали с `Softmax`:\n",
    "\n",
    "$$\n",
    "\\begin{multline*}\n",
    "\\left[ \\operatorname{LogSoftmaxUnidiomatic}(x) \\right]_{ij} =\n",
    "\\log \\left[ \\operatorname{Softmax}(x) \\right]_{ij} = \\\\\n",
    "\\log \\left( \\frac {\\exp(x_{ij})} {\\sum_{k=1}^n \\exp(x_{ik})} \\right) =\n",
    "x_{ij} - \\log\\left( \\sum_{k=1}^n \\exp(x_{ik}) \\right) =\n",
    "x_{ij} - \\log\\left( \\exp(x_{i \\text{, max}}) \\sum_{k=1}^n \\exp(x_{ij} - x_{i \\text{, max}}) \\right) = \\\\\n",
    "x_{ij} - \\left[ x_{i \\text{, max}} + \\log\\left( \\sum_{k=1}^n \\exp(x_{ij} - x_{i \\text{, max}}) \\right) \\right] =\n",
    "\\left[ x_{ij} - x_{i \\text{, max}} \\right] - \\log\\left( \\sum_{k=1}^n \\exp(x_{ij} - x_{i \\text{, max}}) \\right) ,\n",
    "\\end{multline*}\n",
    "$$\n",
    "\n",
    "где $x_{i \\text{, max}} = \\max \\left\\{ x_i \\right\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSoftmaxUnidiomatic(nn.Module):\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 2\n",
    "        <YOUR CODE>\n",
    "\n",
    "assert_identical_forward(nn.LogSoftmax(dim=1), LogSoftmaxUnidiomatic())\n",
    "assert_identical_forward(nn.LogSoftmax(dim=1), LogSoftmaxUnidiomatic(), std=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-control",
   "metadata": {},
   "source": [
    "Наконец, для логарифма знаменателя `Softmax` в PyTorch есть специальная функция `torch.logsumexp`. Воспользуемся ей:\n",
    "\n",
    "$$\n",
    "\\left[ \\operatorname{LogSoftmax}(x) \\right]_{ij} =\n",
    "\\left[ x_{ij} - x_{i \\text{, max}} \\right] - \\left[ \\operatorname{logsumexp} (x_i - x_{i \\text{, max}}) \\right]_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSoftmax(nn.Module):\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 2\n",
    "        <YOUR CODE>\n",
    "\n",
    "assert_identical_forward(nn.LogSoftmax(dim=1), LogSoftmax())\n",
    "assert_identical_forward(nn.LogSoftmax(dim=1), LogSoftmax(), std=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8VRgf3nU44GM",
   "metadata": {},
   "source": [
    "В принципе, можно было бы использовать и более простую формулу:\n",
    "\n",
    "$$\n",
    "\\left[ \\operatorname{LogSoftmax}(x) \\right]_{ij} =\n",
    "x_{ij} - \\left[ \\operatorname{logsumexp} (x) \\right]_{ij}\n",
    "$$\n",
    "\n",
    "но из-за неточности вычислений с плавающей точкой мы не смогли бы свериться с PyTorch, который использует именно предыдущую формулу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-smoke",
   "metadata": {},
   "source": [
    "## 2.5. `nn.NLLLoss`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-folks",
   "metadata": {},
   "source": [
    "Вспомним, что, решая задачу классификации, мы всего лишь пытаемся максимизировать предсказываемый логарифм вероятности для истинного класса (или, что то же самое, минимизировать минус логарифм). На выходе нашего классификатора будет матрица, где по строкам будут разные сэмплы, а по столбцам логарифмы вероятностей для каждого из классов.\n",
    "\n",
    "$$\n",
    "\\operatorname{NLLLoss}(p, c) = - \\frac 1 n \\sum_{i = 1}^n p_{i, c_i}\n",
    "$$\n",
    "\n",
    "Чтобы максимизировать вероятности истинных классов, надо их выбрать из такой матрицы. В PyTorch можно это сделать так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = DivideBySum()(torch.rand(5, 3))\n",
    "c = torch.randint(3, (5,))\n",
    "print('p:\\n', p)\n",
    "print('c:\\n', c)\n",
    "print('p indexed by c:\\n', p[torch.arange(5), c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-helicopter",
   "metadata": {},
   "source": [
    "А теперь реализуем собственно `NLLLoss`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLLLoss(nn.Module):\n",
    "    def forward(self, predicted_probs, true_classes):\n",
    "        batch_size = predicted_probs.shape[0]\n",
    "        <YOUR CODE>\n",
    "\n",
    "for _ in range(10):\n",
    "    p = DivideBySum()(torch.rand(10, 3))\n",
    "    c = torch.randint(3, (10,))\n",
    "    assert torch.allclose(nn.NLLLoss()(p, c), NLLLoss()(p, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-roman",
   "metadata": {},
   "source": [
    "## 2.6. `nn.CrossEntropyLoss`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-onion",
   "metadata": {},
   "source": [
    "`CrossEntropyLoss` — это всего лишь `LogSoftmax`, за которым идёт `NLLLoss`. Но мы реализуем ещё несколько вариантов, чтобы убедиться, что они работают хуже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLossVeryUnstable(nn.Module):\n",
    "    def forward(self, predicted_logits, true_classes):\n",
    "        # Используйте LogSoftmaxVeryUnstable\n",
    "        <YOUR CODE>\n",
    "\n",
    "for _ in range(10):\n",
    "    logits = torch.randn(10, 3)\n",
    "    c = torch.randint(3, (10,))\n",
    "    assert torch.allclose(nn.CrossEntropyLoss()(logits, c), CrossEntropyLossVeryUnstable()(logits, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLossUnstable(nn.Module):\n",
    "    def forward(self, predicted_logits, true_classes):\n",
    "        # Используйте LogSoftmaxUnstable\n",
    "        <YOUR CODE>\n",
    "\n",
    "for _ in range(10):\n",
    "    logits = torch.randn(10, 3)\n",
    "    c = torch.randint(3, (10,))\n",
    "    assert torch.allclose(nn.CrossEntropyLoss()(logits, c), CrossEntropyLossUnstable()(logits, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(nn.Module):\n",
    "    def forward(self, predicted_logits, true_classes):\n",
    "        # Используйте LogSoftmax\n",
    "        <YOUR CODE>\n",
    "\n",
    "for _ in range(10):\n",
    "    logits = torch.randn(10, 3)\n",
    "    c = torch.randint(3, (10,))\n",
    "    assert torch.allclose(nn.CrossEntropyLoss()(logits, c), CrossEntropyLoss()(logits, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-springer",
   "metadata": {},
   "source": [
    "## 2.7. `nn.Linear`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-corrections",
   "metadata": {},
   "source": [
    "Наконец займёмся самой важной частью — линейным слоем:\n",
    "\n",
    "$$\n",
    "\\operatorname{Linear}(x) = x \\cdot W + b\n",
    "$$\n",
    "\n",
    "Для этого нам понадобится завести обучаемые параметры `W` и `b`. Будем хранить их прямо внутри класса.\n",
    "\n",
    "Первое желание — это просто положить их в параметры класса как тензоры (`self.weight = torch.tensor(...)`). Так в принципе тоже можно делать, но хотелось бы иметь механизм, позволяющий помечать тензоры внутри класса как обучаемые и необучаемые. В PyTorch такой механизм предоставляет класс `nn.Parameter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        weight = <YOUR CODE>\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        bias = <YOUR CODE>\n",
    "        self.bias = nn.Parameter(bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-transcript",
   "metadata": {},
   "source": [
    "## 2.8 Уже можно собрать модель!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = <YOUR CODE>  # линейный слой с 10 входами и 5 выходами\n",
    "        self.relu = <YOUR CODE>\n",
    "        self.fc2 = <YOUR CODE>  # линейный слой с 5 входами и 1 выходом\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Примените последовательно все три слоя и верните результат\n",
    "        <YOUR CODE>\n",
    "\n",
    "my_model = MyModel()\n",
    "x = torch.randn(3, 10)\n",
    "y = my_model(x)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-motor",
   "metadata": {},
   "source": [
    "## 2.9. Но лучше всё-таки ещё сделать `nn.Sequential`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-drink",
   "metadata": {},
   "source": [
    "Чтобы сделать контейнер для нескольких слоёв, запускающихся последовательно, достаточно сложить все эти слои внутрь класса. Для этого в PyTorch есть `nn.ModuleList`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.submodules = nn.ModuleList(args)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-spectrum",
   "metadata": {},
   "source": [
    "# 3. И ещё раз собираем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Такая же модель, как выше, но через наш Sequential\n",
    "my_model = <YOUR CODE>\n",
    "\n",
    "x = torch.randn(3, 10)\n",
    "y_pred = my_model(x)\n",
    "print(y_pred)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-encounter",
   "metadata": {},
   "source": [
    "# 4. `torch.optim.SGD`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-belarus",
   "metadata": {},
   "source": [
    "Оптимизатор получает на вход список из обучаемых параметров модели. У наследников класса `nn.Module` его можно получить через метод `.parameters()`. От оптимизатора мы хотим два метода: `.step()` и `.zero_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, parameters, lr):\n",
    "        self.model_parameters = list(parameters)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.model_parameters:\n",
    "                if p.grad is not None:\n",
    "                    dL_dp = p.grad\n",
    "                    <YOUR CODE>\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.model_parameters:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-passion",
   "metadata": {},
   "source": [
    "# 5. Датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-passenger",
   "metadata": {},
   "source": [
    "В этот раз поэкспериментируем на [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). По формату он точно такой же как MNIST (60k картинок в трейне, 10k для валидации, 10 классов, чёрно-белые картинки размером 28x28 пикселей), но на MNIST можно элементарно получить точность 97%, а на FashionMNIST сходу можно набрать только где-то 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-words",
   "metadata": {},
   "source": [
    "## 5.1. Скачиваем и смотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.hub import _get_torch_home\n",
    "\n",
    "# На Linux датасет скачается в ~/.cache/torch/datasets, но можете выбрать любую другую папку\n",
    "datasets_path = Path(_get_torch_home()) / 'datasets'\n",
    "\n",
    "dataset_train = torchvision.datasets.FashionMNIST(\n",
    "    datasets_path, train=True, download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ") # используем готовый класс от торча для загрузки данных для тренировки\n",
    "dataset_valid = torchvision.datasets.FashionMNIST(\n",
    "    datasets_path, train=False, download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ") # используем готовый класс от торча для загрузки данных для валидации\n",
    "\n",
    "class_idx_to_name = {\n",
    "    0: \"T-shirt/Top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\", \n",
    "    5: \"Sandal\", \n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "n = 10\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(dataset_train[i][0].squeeze(0).numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.title(class_idx_to_name[dataset_train[i][1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-growing",
   "metadata": {},
   "source": [
    "## 5.2. Делаем функцию для формирования батчей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-softball",
   "metadata": {},
   "source": [
    "Библиотека `torchvision` скачала данные за нас и дала нам такой интерфейс:\n",
    "\n",
    "```\n",
    "dataset[i] = (tensor(shape=(1, 28, 28)), int)\n",
    "              \\_______________________/  \\_/\n",
    "                          x               y\n",
    "```\n",
    "\n",
    "Порядок размерностей у картинок в PyTorch `CHW` (`channel`, `height`, `width`; в Tensorflow используется `HWC`). Здесь шейп у тензоров `(1, 28, 28)`, то есть у картинок 1 цветовой канал и размеры 28x28 пикселей.\n",
    "\n",
    "Нам понадобится функция, которая принимает на вход список индексов элементов датасета и выдаёт батч из соответствующих элементов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch_from_indices(dataset, indices):\n",
    "    images = []\n",
    "    targets = []\n",
    "    for j in indices:\n",
    "        image, target = dataset[j]\n",
    "        images.append(image)\n",
    "        targets.append(target)\n",
    "\n",
    "    x_batch = torch.stack(images, dim=0)\n",
    "    y_batch = torch.tensor(targets, dtype=torch.int64)\n",
    "    \n",
    "    return x_batch, y_batch\n",
    "\n",
    "x_batch, y_batch = make_batch_from_indices(dataset_valid, [0, 3, 100, 500, 800, 5000, 9001])\n",
    "print(x_batch.shape)\n",
    "print(y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-synthesis",
   "metadata": {},
   "source": [
    "# 6. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 200\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-union",
   "metadata": {},
   "source": [
    "## 6.1. Создаём все нужные объекты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-upper",
   "metadata": {},
   "source": [
    "Воспользуемся всем, что мы уже написали, и создадим нейронку с $28^2$ числами на входе, $128$ промежуточными активациями и $10$ (по количеству классов) числами на выходе. В качестве функции активации возьмём `ReLU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_model():\n",
    "    <YOUR CODE>\n",
    "\n",
    "model = make_new_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-bowling",
   "metadata": {},
   "source": [
    "Попробуем разные варианты для `criterion`: `CrossEntropyLossVeryUnstable`, `CrossEntropyLossUnstable` и, наконец, `CrossEntropyLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-purple",
   "metadata": {},
   "source": [
    "Наш оптимизатор!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-moral",
   "metadata": {},
   "source": [
    "## 6.2. Запускаем обучающий цикл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(range(1, num_epochs + 1)) as progress_bar:\n",
    "    for epoch in progress_bar:\n",
    "        # Обучение\n",
    "\n",
    "        # Создаём случайную перестановку индексов обучающего датасета\n",
    "        indices_train = <YOUR CODE>\n",
    "\n",
    "        for i in range(0, len(dataset_train), batch_size):\n",
    "            # Формируем батч\n",
    "            batch_indices = indices_train[<YOUR CODE>]  # выбираем очередную порцию индексов...\n",
    "            x_batch, y_batch = make_batch_from_indices(dataset_train, batch_indices)  # ... и строим по ней батч\n",
    "\n",
    "            # flatten: (B, 1, 28, 28) -> (B, 28 * 28)\n",
    "            x_batch = <YOUR CODE>\n",
    "\n",
    "            y_pred = <YOUR CODE>  # делаем предсказания\n",
    "            loss = <YOUR CODE>  # считаем лосс\n",
    "\n",
    "            assert np.isfinite(loss.item())  # проверяем, что всё посчиталось корректно\n",
    "\n",
    "            # Считаем градиенты и делаем шаг оптимизатора, не забыв обнулить градиенты\n",
    "            <YOUR CODE>\n",
    "\n",
    "        # Валидация\n",
    "            \n",
    "        valid_losses = []  # сюда будем складывать средний лосс по батчам\n",
    "        valid_accuracies = []\n",
    "        # мы считаем качество, поэтому мы запрещаем фреймворку считать градиенты по параметрам\n",
    "        with torch.no_grad():\n",
    "            # Создаём список из индексов валидационного датасета (перемешивать их не обязательно)\n",
    "            indices_valid = <YOUR CODE>\n",
    "            \n",
    "            for i in range(0, len(dataset_valid), batch_size):\n",
    "                # Формируем батч\n",
    "                batch_indices = indices_valid[<YOUR CODE>]\n",
    "                x_batch, y_batch = make_batch_from_indices(dataset_valid, batch_indices)\n",
    "                \n",
    "                x_batch = <YOUR CODE> # flatten\n",
    "                y_pred = <YOUR CODE> # делаем предсказания\n",
    "                loss = <YOUR CODE> # считаем лосс\n",
    "                \n",
    "                valid_losses.append(loss.numpy()) # добавляем в массив\n",
    "                valid_accuracies.extend((torch.argmax(y_pred, dim=-1) == y_batch).numpy().tolist())\n",
    "\n",
    "        # выводим статистику\n",
    "        valid_loss = np.mean(valid_losses)\n",
    "        valid_accuracy = np.mean(valid_accuracies)\n",
    "        stats = f'loss: {valid_loss:.5f}, accuracy: {valid_accuracy:.4f}'\n",
    "        print(f'Epoch: {epoch}, {stats}')\n",
    "        progress_bar.set_postfix_str(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-killer",
   "metadata": {},
   "source": [
    "## 6.3. Смотрим на результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 10\n",
    "cols = 10\n",
    "\n",
    "f, axarr = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        idx = i * cols + j\n",
    "        axarr[i, j].imshow(dataset_valid[idx][0].squeeze(0).numpy().reshape([28, 28]), cmap='gray')\n",
    "        y_true = dataset_valid[idx][1]\n",
    "        y_pred = torch.argmax(model(dataset_valid[idx][0].reshape(1, 784)).squeeze(0), dim=-1).item()\n",
    "        axarr[i, j].set_title(class_idx_to_name[y_pred], color='black' if y_true == y_pred else 'red')\n",
    "\n",
    "for ax in f.axes:\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "f.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-supervisor",
   "metadata": {},
   "source": [
    "# 7. `torch.utils.data.DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-conservative",
   "metadata": {},
   "source": [
    "Поработав руками с индексами, можно видеть, почему `DataLoader` — удобная абстракция. Реализуем его руками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-mauritius",
   "metadata": {},
   "source": [
    "## 7.1. Пишем свой `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CuP66VswB06f",
   "metadata": {},
   "source": [
    "Надо завернуть в класс следующие штуки:\n",
    "\n",
    "1. Создание и перемешивание списка индексов;\n",
    "2. Вызов функции `make_batch_from_indices()`;\n",
    "3. Отслеживание текущего положения итератора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataset) / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return DataLoaderIter(self)\n",
    "\n",
    "class DataLoaderIter:\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataset = dataloader.dataset\n",
    "        self.indices = np.arange(len(self.dataset))\n",
    "        if dataloader.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        self.batch_size = dataloader.batch_size\n",
    "        self.position = 0\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.position >= len(self.indices):\n",
    "            raise StopIteration\n",
    "\n",
    "        # Вызываем make_batch_from_indices() с правильными аргументами\n",
    "        x_batch, y_batch = <YOUR CODE>\n",
    "        \n",
    "        # Обновляем self.position\n",
    "        <YOUR CODE>\n",
    "\n",
    "        return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-adaptation",
   "metadata": {},
   "source": [
    "## 7.2. Переписываем обучающий цикл со своим `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = <YOUR CODE>\n",
    "valid_dataloader = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_new_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(range(1, num_epochs + 1)) as progress_bar:\n",
    "    for epoch in progress_bar:\n",
    "        # Трейн\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            # Батчи приезжают из даталоадера уже готовыми, их достаточно только решейпнуть\n",
    "\n",
    "            # flatten: (B, 1, 28, 28) -> (B, 28 * 28)\n",
    "            x_batch = <YOUR CODE>\n",
    "\n",
    "            y_pred = <YOUR CODE>  # делаем предсказания\n",
    "            loss = <YOUR CODE>  # считаем лосс\n",
    "\n",
    "            assert np.isfinite(loss.item())  # проверяем, что всё посчиталось корректно\n",
    "\n",
    "            # Считаем градиенты и делаем шаг оптимизатора, не забыв обнулить градиенты\n",
    "            <YOUR CODE>\n",
    "            \n",
    "        # Валидация\n",
    "        valid_losses = []\n",
    "        valid_accuracies = []\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dataloader:\n",
    "                # Батчи приезжают из даталоадера уже готовыми, их достаточно только решейпнуть\n",
    "                \n",
    "                x_batch = <YOUR CODE> # flatten\n",
    "                y_pred = <YOUR CODE> # делаем предсказания\n",
    "                loss = <YOUR CODE> # считаем лосс\n",
    "\n",
    "                valid_losses.append(loss.numpy())\n",
    "                valid_accuracies.extend((torch.argmax(y_pred, dim=-1) == y_batch).numpy().tolist())\n",
    "\n",
    "        valid_loss = np.mean(valid_losses)\n",
    "        valid_accuracy = np.mean(valid_accuracies)\n",
    "        stats = f'loss: {valid_loss:.5f}, accuracy: {valid_accuracy:.4f}'\n",
    "        print(f'Epoch: {epoch}, {stats}')\n",
    "        progress_bar.set_postfix_str(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-virgin",
   "metadata": {},
   "source": [
    "В заключение обсудим технические вопросы. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-growth",
   "metadata": {},
   "source": [
    "# 8. GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-output",
   "metadata": {},
   "source": [
    "В PyTorch каждый тензор физически находится в памяти, принадлежащей какому-то устройству: RAM (которую контролирует CPU) или в GPU-памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(1)\n",
    "a.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-diabetes",
   "metadata": {},
   "source": [
    "В Colab по умолчанию выключена GPU, чтобы экономить ресурсы Гугла. Если вы смотрите этот ноутбук через Colab, то нажмите `Runtime` -> `Change runtime type` и в списке выберите `GPU`. Это перезагрузит ваш ноутбук, и вам придётся перезапустить какие-то из ячеек выше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-custom",
   "metadata": {},
   "source": [
    "Когда у вас есть работающая GPU, тензор можно одной командой туда перенести:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.to(device)\n",
    "a.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-muslim",
   "metadata": {},
   "source": [
    "Обратно тоже можно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.to('cpu')  # или a.cpu()\n",
    "a.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-gnome",
   "metadata": {},
   "source": [
    "Аналогично можно делать и с целыми моделями, хранящими в себе много тензоров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_new_model()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-chapter",
   "metadata": {},
   "source": [
    "У модели нет поля `.device`, потому что разные тензоры, из которых состоит модель, могут лежать на разных устройствах (например, на разных видеокартах).\n",
    "\n",
    "Создание оптимизатора не меняется:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HWT0e3s7Ek2H",
   "metadata": {},
   "source": [
    "В обучающем цикле понадобится:\n",
    "\n",
    "1. После получения батчей из `DataLoader` перенести их на GPU;\n",
    "2. После вычисления метрик перенести их обратно в оперативную память."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(range(1, num_epochs + 1)) as progress_bar:\n",
    "    for epoch in progress_bar:\n",
    "        # Трейн\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            # flatten: (B, 1, 28, 28) -> (B, 28 * 28)\n",
    "            x_batch = <YOUR CODE>\n",
    "\n",
    "            # Переносим батч на GPU\n",
    "            x_batch = <YOUR CODE>\n",
    "            y_batch = <YOUR CODE>\n",
    "\n",
    "            y_pred = <YOUR CODE>  # делаем предсказания\n",
    "            loss = <YOUR CODE>  # считаем лосс\n",
    "\n",
    "            assert np.isfinite(loss.item())  # .item() сделает .to('cpu') за нас\n",
    "\n",
    "            # Считаем градиенты и делаем шаг оптимизатора, не забыв обнулить градиенты\n",
    "            <YOUR CODE>\n",
    "\n",
    "        valid_losses = []\n",
    "        valid_accuracies = []\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dataloader:\n",
    "                x_batch = <YOUR CODE> # flatten\n",
    "\n",
    "                # Переносим батч на GPU\n",
    "                x_batch = <YOUR CODE>\n",
    "                y_batch = <YOUR CODE>\n",
    "\n",
    "                y_pred = <YOUR CODE> # делаем предсказания\n",
    "                loss = <YOUR CODE> # считаем лосс\n",
    "\n",
    "                valid_losses.append(loss.item())  # .item() сделает .to('cpu') за нас\n",
    "                # В следующей строке добавилось .to('cpu')\n",
    "                valid_accuracies.extend((torch.argmax(y_pred, dim=-1) == y_batch).to('cpu').numpy().tolist())\n",
    "\n",
    "        # выводим статистику\n",
    "        valid_loss = np.mean(valid_losses)\n",
    "        valid_accuracy = np.mean(valid_accuracies)\n",
    "        stats = f'loss: {valid_loss:.5f}, accuracy: {valid_accuracy:.4f}'\n",
    "        print(f'Epoch: {epoch}, {stats}')\n",
    "        progress_bar.set_postfix_str(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-hometown",
   "metadata": {},
   "source": [
    "На такой маленькой модели, как эта, мы не увидим ускорение из-за использования GPU и, скорее всего, обучение даже немного замедлится из-за копирования данных между RAM и GPU. Но на больших моделях выигрыш в скорости может достигать сотен раз."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-mirror",
   "metadata": {},
   "source": [
    "# 9. I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-cornwall",
   "metadata": {},
   "source": [
    "## 9.1. Сохранение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-stock",
   "metadata": {},
   "source": [
    "У `nn.Module` есть метод `state_dict()`, возвращающий словарь со всеми тензорами, сидящими в модели. Ключи в этом словаре соответствуют названиям полей, в которых тензоры находятся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "\n",
    "print(type(state_dict))\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-humidity",
   "metadata": {},
   "source": [
    "Функция `torch.save` умеет сохранять стейт дикты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "model_path = Path('/tmp/state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state_dict, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-treaty",
   "metadata": {},
   "source": [
    "## 9.2. Загрузка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-limitation",
   "metadata": {},
   "source": [
    "Функция `torch.load` загружает стейт дикты. По умолчанию она это делает на то же устройство, откуда они были сохранены — например, если тензоры находились на GPU, то и загрузятся они на GPU. Можно это переопределить с помощью параметра `map_location`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "print(type(state_dict))\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-arlington",
   "metadata": {},
   "source": [
    "Чтобы загрузить стейт дикт в модель, у `nn.Module` есть метод `load_state_dict`. Кстати, им же можно копировать параметры из одной модели в другую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-darwin",
   "metadata": {},
   "source": [
    "# 10. Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-nepal",
   "metadata": {},
   "source": [
    "Наберите **accuracy ≥ 0.87** на валидационной выборке FashionMNIST. Нельзя пользоваться никакими классами из `torch.nn.*` и `torch.optim.*`, кроме вспомогательных, наподобие `torch.nn.Parameter`. Разумеется, нельзя учиться на валидации.\n",
    "\n",
    "Что может сработать:\n",
    "\n",
    "1. Реализуйте более продвинутый оптимизатор: Momentum (возможно, с поправкой Нестерова), RMSProp или Adam.\n",
    "2. Поэкспериментируйте с архитектурой: увеличьте глубину или ширину сети или замените функции активации¹.\n",
    "3. Реализуйте [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html). Обратите внимание, что у него разное поведение во время обучения и на валидации: см. документацию на [`nn.Module.train()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train) и [`nn.Module.eval()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval).\n",
    "\n",
    "¹ Если вы решите самостоятельно реализовать `nn.Sigmoid`, вероятно, у вас не получится обойтись автоматическим дифференцированием, и сгенерированный фреймворком `.backward()` будет сохранять в градиенты `nan`. В этом случае вам придётся вручную написать функцию `backward()` для сигмоиды. Наследники `nn.Module` такое не поддерживают, и вам понадобится отнаследоваться от [`Function`](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function). Ничего сложного там нет, но надо будет посмотреть документацию.\n",
    "\n",
    "В качестве решения мы ожидаем от вас **два файла по отдельности (не в архиве)**:\n",
    "\n",
    "1. Ноутбук с кодом (можно дописывать прямо в этот);\n",
    "2. Файл с весами обученной модели.\n",
    "\n",
    "Из ноутбука должно быть понятно, как загрузить ваши веса и полученной моделью посчитать accuracy.\n",
    "\n",
    "Удачи!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "<YOUR CODE>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
